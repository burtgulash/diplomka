\documentclass[11pt]{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[czech]{babel}
\usepackage{a4wide}
\usepackage[numbers]{natbib}
\usepackage[pdfborder={0 0 0},colorlinks=true,linkcolor=green]{hyperref}
\usepackage[bottom=2.5cm]{geometry}

\linespread{1.15}


\begin{document}
\section{Úvod}
Díky vzestupu počítačů a především internetu došlo k dramatickému
nárustu objemu textových informací ve formě snadno přístupné lidem i pro
počítačové zpracování. Textová data jsou specifická v tom, že jejími
tvůrci jsou lidé a ne počítačové systémy nebo měřící čidla. 

\section{Východiska}
V této práci se snažím najít alternativní způsoby v širokém oboru vyhledávání
informací, které nejsou velmi známé, ale osobně si myslím, že na některé
problémy v dnešní době jsou vhodnější než běžně známé metody dostupné v
populární literatuře na webu v článcích a blogových příspěvcích. V této části
se pokusím v krátkosti přiblížit tento základ, na který bude navazovat jádro mé
práce.

\subsection{Databáze a textové vyhledávání}
Textové vyhledávání se často uvádí odděleně od databázových systémů, přestože
by v ideálním případě mělo být součástí databází. Důvodem je silně různorodá
povaha textových dat s nejednoznačným způsobem zacházení. Pokud v databázích
pracujeme například s čísly, pak je situace celkem snadná, protože čísla jsou
snadno a jednoznačně porovnatelná, ať už to jsou floating nebo celá čísla. Jiné
datové typy jako třeba intervaly jsou složitější, ale přesto existují pevně
definovatelné způsoby pro jejich seřazení a tedy snadné vyhledávání.
Intervalovými daty mohou být jednorozměrné časové rozmezí, dvourozměrná
geografická data, nebo vícerozměrná data často používaná v počítačové grafice.
Existuje pro ně velké množství relativně efektivních algoritmů a aktivní
výzkum. Časová data jsou na první pohled lehce seřaditelná, jenže kvůli lidským
"obohacením", jako jsou časové zóny, letní čas, nebo více dimenzí času (čas
platnosti, čas záznamu) se jejich zacházení v databázích komplikuje. Textová
data generovaná lidskou řečí jsou ještě komplikovanější a často se řeší mimo
databázové systémy. Ve výsledku používá spousta uživatelských aplikací s
databázovou podporou ve skutečnosti dva systémy - kromě klasické databáze ještě
speciální systém pro relevantní a efektivní textové vyhledávání.

Problém s textem, který nás zajímá, je jeho nejednoznačná seřaditelnost.
Představme si databázi lidských jmen a aplikaci určenou pro vyhledávání v nich.
Počítá se s tím, že pokud vyhledáváme konkrétní osobu, nevíme přesně jak je
její jméno v databázi uloženo. Kdybychom věděli, že se Jaromír Kobliha v
databázi vyskytuje v konkrétním tvaru Jaromír Kobliha nebo Kobliha, Jaromír
nebo Dr. Jarda Kobliha, pak jednoduše zadáme dotaz na přesnou shodu a máme
vyřešeno. Jenže naše očekávání jsou jiná. Člověk by všechny tyto tvary jména
vyhodnotil ekvivalentně, a tím pádem je naším úkolem vytvořit podobně chytrý
systém anebo alespoň iluzi takového systému. 

Jména mohou být jednoduše rozdělena na více sloupců - křestní jméno, prostřední
jméno, příjmení, titul(y), tak jak to známe, pokud vyplňujeme kdejaké
formuláře. To umožní systému provést oddělený dotaz v každém tomto sloupci a
sloučit výsledky. Nebo jména seřadit nejprve podle příjmení, pak podle jména a
titulů naposled (Kobliha, Jaromír, Dr.), protože předpokládáme, že existuje
méně příjmení než křestních jmen a ještě méně titulů. Tohle je ovšem jenom
heuristika, kterou nelze aplikovat např. ve Vietnamu (Nguyen a Tran tvoří 50\%
všech příjmení) nebo v Jižní Korey (Kim, Lee, Park a Choi tvoří 50\% všech
příjmení). Jiné kultury nemají ani koncept příjmení, proto je takový systém
obecně nedostatečný.

Pro větší záznamy - celé dokumenty o několika stovkách až tisících slov - nelze
ani uvažovat seřaditelnost podobně naivním způsobem. Přestože je vyhledávání v
textu obtížné, existují možnosti, jak povahu lidského textu využít a vytvořit
algoritmy umožňující efektivní vyhledávání.

Statisticky můžeme pozorovat unikátní povahu lidského jazyka v několika statistických pozorováních.
% Frekvenční analýza - codebreaking
% 1, 2,3 - více jedničěk distribuce
% zipf distribuce slov
% redundance - deflate a jiný textový komprese

\subsection{Algoritmy a datové struktury pro textové vyhledávání}
Algoritmy pro vyhledávání využívají právě této redundance v textu a díky tomu
dosahují daleko větší efektivity než o kdybychom textu uvažovali jako o
rovnoměrně rozložených datech.

\subsection{Invertovaný index}
Centrální datovou strukturou, která využívá Zipfovy distribuce slov je tzv.
invertovaný index, nebo také invertovaný soubor.

\subsection{Hledání v invertovaném indexu}
% implicitní vs explicitní operátory
Vstupním dotazem se rozumí posloupnost slov (dotazovaná slova) a
speciálních operátorů. Pro každé vstupní dotazované slovo se provede
dotaz na první část indexu - slovník. Ten vrátí všechny údaje nezbytné k
tomu, abychom získali odpovídající invertovaný seznam dokumentů. V
případě prefixového a přibližného dotazu slovník vrátí celou množinu
odpovídajících slov.  V druhé fázi vyhledávání se použijí nalezené
invertované seznamy a provedou se s nimi operace dle operátorů v dotazu
uživatele. Třetí fází je seřazení výsledků podle zvolené hodnotící
funkce a sesbírání důkazů pro ty výsledky, které budou zobrareny
uživateli.

Invertované indexy podporují několik operací, se kterými může uživatel
měnit povahu svého dotazu. Nejčastěji jsou implementovány booleovské
operátory AND, OR, NOT a frázové vyhledávání - tedy omezení jen na ty
výsledky, kde se slova vyskytují těsně u sebe.

Apache Lucene operátory - fuzzy (nízká účinnost), změna ranku, ...

Pro naše požadavky, především kvůli jednoduchosti, bude postačovat
operátor AND, který navíc bude implicitní v dotazu. Tedy vstupním
dotazem bude posloupnost slov a výsledkem bude konjunkce výsledků
nalezených pro každé z nich. Funkcionalita disjunktivních dotazů
(operátor OR) bude implicitní v tom, že vyhledání slova ve slovníku
vrátí disjunkci více přibližných slov nebo prefixů v případě prefixového
dotazu.  Operátoru NOT je občas potřeba, pokud dojde k nejednoznačnostem
ve výsledcích.  Uživatel může nejednoznačnost identifikovat a zadat
další dotaz, kde ji vyfiltruje právě pomocí operátoru NOT. Otázkou je,
zda-li by se mělo použítí operátoru NOT řídit stejnými pravidly jako u
běžného dotazovaného slova. Pokud by se použila množina slov v blízkosti
negovaného slova, mohlo by dojít k nežádoucímu přílišnému filtrování.

Poté, co v první části indexu - slovníku - nalezneme slova odpovídající
dotazovaným slovům a jejich invertované seznamy, přichází část, kdy se
provedou zadané operace s invertovanými seznamy.  Existují dvě hlavní
možnosti - 1.  zpracovat nejprve každé slovo zvlášť a sloučit výsledek
(Term At A Time - TAAT) nebo 2. postupovat dokument po dokumentu napříč
všemi slovy (Document At A Time
- DAAT).

\subsection{Alternativní datové struktury}
Invertovaný index je doposud vítězem v rychlosti vyhledávání v textu,
ale pro některé speciální případy byly navrženy i jiné datové struktury,
které dokáží být kompaktnější než invertovaný index po kompresi, nebo
umožňují vícero seřazení při jednom uložení v paměti. Klasický
invertovaný index má právě jedno seřazení - nejčastěji podle
vzrůstajícího id dokumentů nebo podle klesající zvolené business
metriky.

Waweletové stromy - dual sorted Index Treap Index

Obě tyto alternativní datové struktury dosahují obrovských úspor díky
své kompresibilitě, čehož bychom využili, pokud bychom uvažovali
rozsáhlá vstupní data. Ale protože se zaměřuji na relativně malé objemy
dat, avšak s vysokou redundancí při prohledávání, nevyužiji tyto datové
struktury. Dalším velkým důvodem je, že jsem nenašel žádný výzkum, který
by je aplikoval na prefixové, natož přibližné vyhledávání. Na druhou
stranu existuje více výzkumných týmů, kteří se zabývají přibližným
(fuzzy) prohledáváním na modifikovaném invertovaném indexu.

\section{Motivace}
Od dotcom bubliny v roce 2000 uplynulo už šestnáct let, Google nedávno
osmnácté narozeniny a od spuštění World Wide Webu uplynuly již téměř tři
desetiletí. V této kapitole nastíním situaci v textovém vyhledávání za
posledních zhruba dvacet let, některé nové trendy a subjektivní
zhodnocení současného stavu, které mě vedlo k této práci.

% Historie 90. - dnes
\subsection{Historie}

\subsection{Folklórní povědomí; Google, Stanford bias; nedostupnost populárních zdrojů (coursera, youtube)}
Právě populární folklórní povědomí o vyhledávání čerpá ze stejných , které čerpají
z běžně dostupných zdrojů.

\subsection{Situace v Open Source}
\subsection{Optimismus v Big Data}

% popiš online processing (agrep), like operátor v databázi?
% regex search. Těžký pro uživatele. Nebere v potaz překlepy


\subsection{Optimismus v umělou inteligenci}
V dnešní době panuje velký optimismus z umělé inteligence a mnozí
předpovídají počítačové systémy schopné porozumět lidské řeči v
nejbližších letech až desetiletích. Nicméně při pohledu do historie
oboru umělé inteligence si můžeme povšimnout více podobných
optimistických období, které ale očekávání nenaplnily a po opadnutí
nadšení přišla tzv. zima v umělé inteligenci (AI winter). 


% Google + statistical bias + big data
% stuck at google's dominance
% bias toward statistical approaches and clever scraping
% some commercial systems and research is catching up
% open source is lagging behind
% what can be done

[1] \url{https://en.wikipedia.org/wiki/Information_retrieval#History}


[1] \url{https://www.theguardian.com/commentisfree/2015/apr/18/google-eu-monopoly-inquiry-too-late-to-stop}

\subsection{Databáze a fulltext}
% 2 paralelní systémy - db + index
\subsection{Open Source a komerční systémy}
% lucene, elastic, solr, algolia, xapian, mnogosearch, postgres


\section{Změny a nové potřeby}
\subsection{Změny v architekturách počítačů a počítačových systémů}
% Stonebraker o databázích
% sloupcové a in-memory db
% něco o nosql
% hierarchie paměti
% ssd
% nvram

% konvergence db a fulltextu. Podobnost se sloupcovými db. Not yet because of
% reasons below. Columnar dbs for analytical slow access. tens of thousands
% columns needed for each word. If some words have short inverted list, then
% waste,because blocks have minimum size.

\subsection{Nové potřeby ve vyhledávání}
\subsection{Vertikální vyhledávání}
Dle hlavního vedoucího výzkumu v Googlu, Petera Norviga, je úspěch Googlu
založen ne na lepších algoritmech, než by měli ostatní, ale jednoduše tím, že
má více dat.
% přístup googlu - chytré scrapování. Přitom data existují ve zpracované formě.
% Nedostatek vertikálního a site search? Špatné nebo obtížné open source
% řešení? 
\subsection{Linked data}
\subsection{Mobilní zařízení}

\subsection{Big data vs Small data}

\subsection{Ohodnocení výsledků dotazu}
\subsection{tf-idf}
% SEO - exploit of google's algorithms. Více vyhledávačů ztěžuje SEO
\subsection{Proximity}
% kritika tf-idf
% alternativa proximity

\section{Přibližné vyhledávání}
% Návrh 

\subsection{Autocompletion}
% query logs

\subsection{Type-ahead search, search as you go}

\url{https://swtch.com/~rsc/regexp/regexp4.html}
\subsection{Prefixové indexy}
% completesearch

\subsection{Lematizace, Stematizace}
Problémy vícejazyčných textů. Detekce jazyka.

\subsection{N-gramový invertovaný index}
% word based vs ngram based
Alternativně při použití trigramů (n-gramy, kde n = 3), by "slova" byla
\textbf{\_\_m, \_má, \_mám, áma, ma\_, a\_m, \_me, mel, ele, le\_, e\_m, \_ma,
mas, aso, so\_, o\_\_}. Ngramové indexy mají tu výhodu, že bez jakýchkoliv
dalších úprav s nimi lze vyhledávat přibližně. 

\subsection{Indexy založené na editovací vzdálenosti}
% tastier

\section{Návrh implementace vyhledávacího systému}
\subsection{Prefixové a fuzzy požadavky}
Ačkoliv se jedná o dva různé požadavky, prefixové a fuzzy invertované indexy
mají ve výsledku podobné vlastnosti a tudíž jsou pro ně vhodné stejné datové
struktury. Pokud na chvíli necháme fuzzy požavky stranou, nastíním, jak lze
jednoduše rozšířit klasický invertovaný index o podporu prefixového
vyhledávání.

Invertovaný index má dvě hlavní části - slovník a tzv. invertovaný soubor.
Slovník obsahuje všechna slova nalezená ve zdrojovém textu a odkazy na
korespondující invertované seznamy v invertovaném souboru. Pro slovníky se
používají buď hashovací tabulky nebo je lze kompaktně uložit jako seřazený
seznam slov. V téhle struktuře se pak pomocí binárního vyhledávání najde
dotazované slovo a zaznamená se jeho pořadí v tomhle seznamu. Odkaz na
invertovaný seznam a další pomocná data pro tohle slovo se naleznou v jiném
seznamu tak, že zaznamenané pořadí se použije jako index do tohohle seznamu.

%\vspace{1cm}
%Příklad:
%
%\begin{center}
%\begin{tabular}{lr}
%\textbf{slovo}   & \textbf{ukazatel} \\
%\hline
%anderson          & 3  \\
%andrea            & 4  \\
%andulka           & 1  \\
%andy              & 2  \\
%kajak             & 13 \\ 
%kamna             & 14 \\
%karafiol          & 6  \\
%karate            & 12 \\ 
%karburátor        & 7  \\
%karel             & 11 \\
%karkulka          & 5  \\
%karma             & 8  \\
%karta             & 9  \\
%karty             & 10 \\ 
%\end{tabular}
%\end{center}

Pro ještě kompaktnější uložení se používá kompresní technika Front-Coding,
která využívá toho, že po sobě následující slova sdílí prefixy. Slovník se
rozdělí na bloky o konstantním počtu slov a prefix se pro tento blok uloží
zvlášť. Například při použití velikosti bloku 4 by slovník se slovy
\textbf{anderson, andrea, andulka, andy, kajak, kamna, karafiol, karate,
karburátor, karel, karkulka, karma, karta, karty} vypadal:
\textbf{\{and\}erson, rea, ulka, y | \{ka\}jak, mna, rafiol, rate | \{kar\}burátor, el, kulka, ma | \{kart\}a, y}

Reprezentace seřazeným seznamem slov je obzvlášť vhodná pro prefixové
vyhledávání, protože v takovém případě stačí nalézt první a poslední slovo ve
slovníku, které odpovídají dotazovanému prefixu. Všechna slova mezi těmito
dvěma odpovídají na prefixový dotaz.

Přibližné vyhledávání slov je s prefixovým podobné, protože většina podobných
slov bude v seřazeném slovníku blízko u sebe. Pokud vyhledáváme přibližná slova
do vzdálenosti 1, pak několik slov se bude lišit v prvním písmenu od
dotazovaného, ale většina rozdílů bude v pozdějších částech slova, a tedy ve
výsledku budou relativně blízko u sebe.

Pro rychlý průchod slovníkem s přibližným prohledáváním se hodí datová
struktura \textbf{kompaktní trie}. Je to vlastně seřazený seznam slov s tím, že
všechny společné prefixy pro všechny skupiny slov jsou uloženy jako rodičovské
uzly stromu n-árního stromu. Tohle rozložení nám umožní rychle dohledat prefix
a všechny jeho potomci ve stromu jsou odpovědí na prefixový dotaz. Přibližné
vyhledávání je efektivní, protože výpočet vzdálenostní funkce se opětovně
použije u všech slov, které sdílí prefix.

Kompaktní trie (ve skutečnosti jakákoliv trie) nám umožní nejen rychlé
vyhledání všech slov odpovídajících prefixu, ale zároveň i rychlé přibližné
vyhledání všech podobných slov podle zvolené distanční metriky.

\subsection{Disjunkce invertovaných seznamů}
\subsection{Hybridní indexy}
\subsection{Indexace}
% 2-pass hybrid
\subsection{Statické a dynamické indexy}
% static: no locks and latches, compact data structures, cache efficient
% 2 level data structure + bulk updates
\subsection{Škálovatelnost}
% document or term based
% share nothing

\section{Ukázka implementace}
\subsection{Použité datové soubory}
\subsection{Demonstrace hybridního indexu}
\subsection{Ukázka vyhledávání}


\section{Závěr}

\section{Odkazy}
\url{http://www.dcs.gla.ac.uk/~craigm/publications/lacour08efficiency.pdf}


% \section{Otevřené problémy}
% \subsection{Příliš krátký vstupní řetězec}



\end{document}
