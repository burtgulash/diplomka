\documentclass[10pt,letterpaper,oneside,openright]{book}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[czech]{babel}
%\usepackage{a4wide}
\usepackage{hyperref}
\usepackage[bottom=2.8cm]{geometry}
\usepackage{color}
\usepackage[numbers]{natbib}
\usepackage[scaled=0.83]{beramono}

\usepackage{tabulary}
\usepackage{subcaption}

\usepackage{fancyvrb}
\usepackage{pygme}

\pagestyle{plain}
\linespread{1.15}
\setlength{\tabcolsep}{1em}

\definecolor{Darkgreen}{rgb}{0,0.4,0}
\hypersetup{%
    pdfborder={0 0 0},
    colorlinks,
    citecolor=blue,
    filecolor=blue,
    linkcolor=blue,
    urlcolor=Darkgreen
}

% \usepackage{sectsty}
% \sectionfont{\fontsize{21}{21}\selectfont}
% \subsectionfont{\fontsize{16}{16}\selectfont}
% \subsectionfont{\fontsize{14}{14}\selectfont}

\makeatletter
\def\@makechapterhead#1{%
    \vspace*{30pt}%
    {\parindent 0pt \raggedright \normalfont
        \interlinepenalty=-1
        \Huge \bfseries \thechapter\hspace{.75em}#1\par\nobreak
        \vskip 40pt
    }}
\makeatother

\newcommand{\bftt}[1]{\texttt{\textbf{#1}}}
\newcommand{\boldred}[1]{\textbf{\color{red} #1}}
\newcommand{\horizlina}%
{
    \mbox{}\vspace{1em}
    \hrule
    \mbox{}
}



\begin{document}
\frontmatter
{\hypersetup{hidelinks}
    \tableofcontents
}

\mainmatter
\chapter{Úvod}
Díky vzestupu počítačů a především internetu došlo k dramatickému nárustu
objemu textových informací ve formě snadno přístupné lidem i pro počítačové
zpracování. Textová data jsou specifická v tom, že jejími tvůrci jsou lidé a ne
počítačové systémy nebo měřící čidla. Při vyhledávání v takovýchto datech máme
jako lidé silná očekávání na relevanci výsledků vyhledávání, nicméně kvůli
charakteristice textových dat je vyhledávání v nich obtížné. Tím, že je úkol
obtížný, existuje více specifických zaměření, než jedno obecné a použitelné pro
všechny případy.

S nástupem World Wide Webu v 90. letech došlo k vzestupu Webových vyhledávačů,
které dnes slouží jako vstupní brána do světa informací.
...

V této práci se snažím najít alternativní způsoby v tomto širokém oboru, které
nejsou velmi známé, a zaměřím se na oblast, která je dle mého názoru jednou z
nejžádanějších v praktických aplikacích. V současné době se pro ni ale
používají techniky pro příliš obecné a zdrojově náročné prohledávání Webu a
nedosahují takových výsledků, jakých by mohly, nebo za příliš vysokou cenu
komplikovaných řešení.

Velkým důvodem proč převažují techniky pro Webové vyhledávání je psychologický
- většina problémů, se kterými se potýkají firmy i nekomerční projekty, zdaleka
nepracuje s takovými objemy dat, se kterým se musí potýkat rozsáhlé webové
vyhledávače nebo světové sociální sítě. V praxi jsou tyto problémy často
řešitelné s použitím pouze jednoho počítače. Nicméně lidé přehnaně věří, že
jejich projekty budou jednou dosahovat obdobných závratných velikostí, a proto
volí řešení nevhodné pro jejich problémy.

V ideálním případě by měla být podpora pro efektivní textové vyhledávání
zabudována přímo do databázových systémů, ale v současné době není jejich
podpora ideální, a proto aplikace s podporou textového vyhledávání používají
kromě databáze ještě paralelní systém specializovaný pro text. Důvod je ten, že
je obtížné vytvořit vyhledávač v takové formě, aby vyhovoval obecným
požadavkům, na které se databáze používají. Techniky představené v této práci
by měly být vhodnější pro generické účely, než ty, které používají Webové
vyhledávače a ze kterých se čerpá inspirace pro textové indexy vestavěné do
databází.

...

V první části uvedu problém vyhledávání v textu, aby čtenář pochopil z jakého
základu tato práce vychází. V druhé části na současný stav v praktickém světě
textového vyhledávání a jak jsme se do něj dostali. Pak se zaměřím na algoritmy
a datové struktury textového vyhledávání a alternativní techniky, které jsou v
některých případech exotické a nepříliš vhodné na obecné použití, ale jiné
které by dle mého názoru zasloužily větší pozornost, protože jejich zaměření
odpovídá současným potřebám více, než na které je v dnešní době kladen největší
důraz. V další části rozeberu vybranou oblast textového vyhledávání více do
hloubky a popíšu problémy, které se v ní vyskytují. Zároveň rozeberu jejich
řešení různými výzkumnými týmy a můj návrh na řešení. V sekci Analýza
kvantitativně poukážu na konkrétní problémy popsané v předchozí sekci a
problémy implementace takového systému. Na závěr představím možná budoucí
řešení a další kroky k vylepšení, aby bylo možné vyhledávací systém nasadit v
praxi.

\chapter{Motivace}

\subsection{Databáze a textové vyhledávání}
Textové vyhledávání se často uvádí odděleně od databázových systémů, přestože
by v ideálním případě mělo být součástí databází. Důvodem je silně různorodá
povaha textových dat s nejednoznačným způsobem zacházení. Pokud v databázích
pracujeme například s čísly, pak je situace celkem snadná, protože čísla jsou
snadno a jednoznačně porovnatelná, ať už to jsou floating nebo celá čísla. Díky
seřaditelnosti pak můžeme použít algoritmus binární vyhledávání, nebo
dynamickou obdobu v podobě binárních vyhledávacích stromů.

Jiné datové typy jako třeba intervaly jsou složitější, ale přesto existují
pevně definovatelné způsoby pro jejich seřazení a tedy snadné vyhledávání.
Intervalovými daty mohou být jednorozměrná časová rozmezí, dvourozměrná
geografická data, nebo vícerozměrná data často používaná v počítačové grafice.
Existuje pro ně velké množství relativně efektivních algoritmů a aktivní
výzkum. Časová data jsou na první pohled lehce seřaditelná, jenže kvůli lidským
"obohacením", jako jsou časové zóny, letní čas, nebo více dimenzí času (čas
platnosti, čas záznamu) se jejich zacházení v databázích komplikuje. Textová
data generovaná lidskou řečí jsou ještě komplikovanější a často se řeší mimo
databázové systémy. Ve výsledku používá spousta uživatelských aplikací s
databázovou podporou ve skutečnosti dva systémy - kromě klasické databáze ještě
speciální systém pro relevantní a efektivní textové vyhledávání.

Problém s textem, který nás zajímá, je jeho nejednoznačná seřaditelnost.
Představme si databázi lidských jmen a aplikaci určenou pro vyhledávání v nich.
Počítá se s tím, že pokud vyhledáváme konkrétní osobu, nevíme přesně jak je
její jméno v databázi uloženo. Kdybychom věděli, že se Jaromír Kobliha v
databázi vyskytuje v konkrétním tvaru Jaromír Kobliha nebo Kobliha, Jaromír
nebo Dr. Jarda Kobliha, pak jednoduše zadáme dotaz na přesnou shodu a máme
vyřešeno. Jenže naše očekávání jsou jiná. Člověk by všechny tyto tvary jména
vyhodnotil ekvivalentně, a tím pádem je naším úkolem vytvořit podobně chytrý
systém anebo alespoň iluzi takového systému.

Jména mohou být jednoduše rozdělena na více sloupců - křestní jméno, prostřední
jméno, příjmení, titul(y), tak jak to známe, pokud vyplňujeme kdejaké
formuláře. To umožní systému provést oddělený dotaz v každém tomto sloupci a
sloučit výsledky. Nebo jména seřadit nejprve podle příjmení, pak podle jména a
titulů naposled (Kobliha, Jaromír, Dr.), protože předpokládáme, že existuje
méně příjmení než křestních jmen a ještě méně titulů. Tohle je ovšem jenom
heuristika, kterou nelze aplikovat např. ve Vietnamu (Nguyen a Tran tvoří 50\%
všech příjmení) nebo v Jižní Korey (Kim, Lee, Park a Choi tvoří 50\% všech
příjmení). Jiné kultury nemají ani koncept příjmení, proto je takový systém
obecně nedostatečný.

Pro větší záznamy - celé dokumenty o několika stovkách až tisících slov - nelze
ani uvažovat seřaditelnost podobně naivním způsobem. Přestože je vyhledávání v
textu obtížné, existují možnosti, jak povahu lidského textu využít a vytvořit
algoritmy umožňující efektivní vyhledávání.

Statisticky můžeme pozorovat unikátní povahu lidského jazyka v několika statistických pozorováních.
% Frekvenční analýza - codebreaking
% 1, 2,3 - více jedničěk distribuce
% zipf distribuce slov
% redundance - deflate a jiný textový komprese

[1] \url{https://en.wikipedia.org/wiki/Information_retrieval#History}
[1] \url{https://www.theguardian.com/commentisfree/2015/apr/18/google-eu-monopoly-inquiry-too-late-to-stop}


\section{Změny v architekturách počítačů a počítačových systémů}
% Stonebraker o databázích
% sloupcové a in-memory db
% něco o nosql
% hierarchie paměti
% ssd
% nvram

% konvergence db a fulltextu. Podobnost se sloupcovými db. Not yet because of
% reasons below. Columnar dbs for analytical slow access. tens of thousands
% columns needed for each word. If some words have short inverted list, then
% waste,because blocks have minimum size.

\subsection{Nové potřeby ve vyhledávání}
\subsection{Vertikální vyhledávání}
Dle hlavního vedoucího výzkumu v Googlu, Petera Norviga, je úspěch Googlu
založen ne na lepších algoritmech, než by měli ostatní, ale jednoduše tím, že
má více dat.
% přístup googlu - chytré scrapování. Přitom data existují ve zpracované formě.
% Nedostatek vertikálního a site search? Špatné nebo obtížné open source
% řešení?
\subsection{Linked data}
\subsection{Mobilní zařízení}



\section{Textové vyhledávání}
Vstupem v úloze vyhledávání je \textbf{dotaz} (query), tedy vstupní textový
řetězec. Výstupem je seznam odpovídajících záznamů (dokumentů) z databáze
seřazený podle ohodnocení, kterou vyhledávací systém přiřadí dle shody
(relevance) dotazu s nalezeným záznamem.

Pokud by dotazem bylo například jediné slovo \bftt{Petr}, mohl by výsledek
vyhledávání v databázi jmen vrátit jména \bftt{Petr Novák, Petr Novotný, Petr
Klíč, Petr Žel, ...}. Dotazem je povětšinou posloupnost jednoho nebo více slov,
ale může obsahovat i různé operátory, které upravují povahu dotazu. Například
booleovské operátory AND, OR a NOT mohou určit zda se musí shodovat všechna
slova, nebo pouze jedno, nebo se slovo vyskytovat nesmí. Např. dotaz
\bftt{Pavel OR Petr AND NOT Novák}. Každý vyhledavač implementuje různé
operátory a kromě těch základních booleovských nejsou jejich funkce nijak
sjednoceny.

Uživatelsky jsou nejpřívětivější vyhledávače, u kterých není třeba speciální
operátory vůbec používat. Vyhledávač si je buďto sami doplní do čistě textového
dotazu, nebo se o vysokou přesnost postarají jejich hodnotící funkce.

\subsection{Relevance}
Pro měření relevance existují dvě základní metriky - přesnost (precision) a
výtěžnost (recall) \url{https://wiki.korpus.cz/doku.php/pojmy:precision}.

Přesnost je poměr počtu relevantních nalezených výsledků ku počtu všech
nalezených výsledků. Tedy vyhledávač bude vyhledávat přesně, pokud bude
obsahovat malé množství výsledků¸ které s dotazem nemají nic společného.
Vyhledávače cílící na přesnost ale mohou trpět tím, že některé záznamy, které
jsou pro uživatele relevantní, nejsou vůbec nalezeny. To měří právě výtěžnost -
tedy poměr počtu relevantních nalezených výsledků ku počtu všech relevantních
záznamů v databázi. Pro relevantní vyhledávání jsou důležité obě hodnoty. Při
malé výtěžnosti bude uživatel cítit frustraci z toho, že musí hloupému
vyhledávači podstrčit více podobných dotazů a stále bude mít pocit, že
vyhledávač nenalezl všechno. Při malé přesnosti bude mít uživatel pocit, že si
vyhledávač vyhledává, co se mu zlíbí.

U relativně malých datových sad, kterými se tato práce zabývá, je narozdíl od
webových vyhledávačů velmi důležitá výtěžnost. Při velkém množství výsledků se
ztratí, že některé dokumenty nebudou nalezeny. V databázi jmen by ale bylo
velmi frustrující, kdyby při dotazu \bftt{Jan Voštěp} nebylo nic nalezeno,
přitom by v databázi existoval záznam \bftt{Dr. Voštěp, Jan}.

\subsection{Invertovaný index}
Centrální datovou strukturou, která navíc využívá ve svůj prospěch Zipfovy
distribuce slov, je datová struktura \textbf{invertovaný index} (nebo také
invertovaný soubor). Princip datové struktury je ten, že pro každé slovo, které
se vyskytuje v databázi, si uložíme seznam odkazů na všechny záznamy
(dokumenty), na kterých se slovo nachází.  Invertovaný index by měl být znám
všem, kdo čtou knihy, protože rejstřík na posledních stránkách není ničím jiným
než právě invertovaným indexem, kde jedním záznamem je stránka knihy a odkazem
je číslo stránky.

Invertovaný index jsou ve skutečnosti dvě datové struktury. Tou první je
takzvaný slovník - tedy seznam všech vyskytujících se slov s odkazem na svůj
příslušný seznam odkazů, neboli invertovaný seznam. Druhou strukturou je
samotný invertovaný soubor, což je soubor všech invertovaných seznamů.

Obě datové struktury mohou být implementovány různými způsoby podle druhu
použití a požadovaných vlastností. Kupříkladu obyčejná hashovací tabulka
poskytne velmi rychlý přístup k hledanému slovu ve slovníku, ale bude zabírat
relativně mnoho paměti, protože každý záznam v tabulce si musí uchovat samotný
text uloženého slova. V textovém vyhledávání, které často pracuje s velkými
objemy dat, bude vhodnější pouhý seřazený seznam slov, na který lze použít
binární vyhledávání. Odpadne nutnost ukládat pomocná data hashovací tabulky a
navíc lze použít jednoduchou kompresní metodu - tzv. front coding. Pořadí slova
v seřazeném seznamu lze použít jako odkaz pro nalezení odpovídajícího
invertovaného seznamu.

Invertovaný index je datová struktura obzvlášť obtížná na úpravy, protože je v
paměti počítače uchována ve velmi kompaktní formě - často s použitím dalších
kompresních algoritmů. Právě díky tomu na druhou stranu dosahuje vyšší
rychlosti čtení oproti obecným vyhledávacím stromům. Index se proto často
nejprve vytvoří (\textbf{indexování}) a pak se používá jen pro čtení.

%\vspace{1cm}
%Příklad:
%
%\begin{center}
%\begin{tabular}{lr}
%\textbf{slovo}   & \textbf{ukazatel} \\
%\hline
%anderson          & 3  \\
%andrea            & 4  \\
%andulka           & 1  \\
%andy              & 2  \\
%kajak             & 13 \\
%kamna             & 14 \\
%karafiol          & 6  \\
%karate            & 12 \\
%karburátor        & 7  \\
%karel             & 11 \\
%karkulka          & 5  \\
%karma             & 8  \\
%karta             & 9  \\
%karty             & 10 \\
%\end{tabular}
%\end{center}

Pro ještě kompaktnější uložení se používá kompresní technika Front-Coding,
která využívá toho, že po sobě následující slova sdílí prefixy. Slovník se
rozdělí na bloky o konstantním počtu slov a prefix se pro tento blok uloží
zvlášť. Například při použití velikosti bloku 4 by slovník se slovy
\bftt{anderson, andrea, andulka, andy, kajak, kamna, karafiol, karate,
karburátor, karel, karkulka, karma, karta, karty} vypadal:
\bftt{\{and\}erson, rea, ulka, y | \{ka\}jak, mna, rafiol, rate | \{kar\}burátor, el, kulka, ma | \{kart\}a, y}

% TODO ukázka invertovaného indexu

\subsection{Alternativní datové struktury}
Invertovaný index je stále nejefektivnější datovou strukturou pro vyhledávání v
textu, ale pro některé speciální případy byly navrženy i jiné datové struktury,
které dokáží být kompaktnější než invertovaný index po kompresi, nebo umožňují
vícero seřazení při jednom uložení v paměti. Klasický invertovaný index má
právě jedno seřazení dokumentů - nejčastěji podle vzrůstajícího id dokumentu.

Waweletové stromy - dual sorted Index Treap Index

Obě tyto alternativní datové struktury dosahují obrovských úspor díky
své kompresibilitě, čehož bychom využili, pokud bychom uvažovali
rozsáhlá vstupní data. Ale protože se zaměřuji na relativně malé objemy
dat, avšak s vysokou redundancí při prohledávání, nevyužiji tyto datové
struktury. Dalším velkým důvodem je, že jsem nenašel žádný výzkum, který
by je aplikoval na prefixové, natož přibližné vyhledávání. Na druhou
stranu existuje více výzkumných týmů, kteří se zabývají přibližným
(fuzzy) prohledáváním na modifikovaném invertovaném indexu.

\section{Techniky pro zvýšení relevance}
Vyhledávání v čistém invertovaném indexu je náchylné k neposkytování všech
výsledků. Velkou příčinou ve webových vyhledávačích vždy byla morfologie jazyka
textu. Dokumenty také mohou obsahovat slova jiného jazyka, který uživatel
příliš neovládá, nebo pouze neví, jak se slovo píše. V případě češtiny to není
takový problém díky podobnosti psaní a výslovnosti (vysoká fonémická
ortografie), ale např. v angličtině se mohou různá slova psát při stejné
výslovnosti různě (red - read, clothes - close, steal - steel) nebo naopak
vyslovovat různě při stejném zápisu (lead - olovo nebo vést). Problémem mohou
být i technické pojmy nebo názvy ( ASUS GTX950-2G, 2GB GDDR5 (grafická karta);
ADATA XPG Z1 8GB (2x4GB) DDR4 2133 CL13 (paměť DRAM); ETA 0028 90040 Gratus Max
(Kuchyňský robot)). V dnešní době to mohou být stále více se zvýšeným
používáním mobilních zařízení (a obtížnějším zadáváním textu) překlepy v
dotazu.

\subsection{Jazyková analýza}
Velkým problémem textových vyhledávačů je tvarosloví jazyka (morfologie - různé
tvary slov, např. dobrý, dobrou, dobrému, dobrých).  Například při dotazování vyhledávače
na výraz \bftt{motorová pila} nás jistě budou zajímat i výsledky, které
obsahují text \bftt{motorové pile} nebo \bftt{motorových pilách}. Nelze po
uživateli požadovat, aby vyjmenoval všechny tvary slov, které zadává.

V češtině a v dalších indoevropských jazycích dochází k nejvíce morfologickým
změnám na koncích slov.  Klasickým řešením je před indexováním dat provést
jazykovou analýzu a převést slova na kmenový tvar (stematizace). Ve výsledku se
místo slova \bftt{motorových} zaindexuje slovo \bftt{motor} a poté při
vyhledávání se provede tatáž konverze dotazovaných slov. Vyhledávač by tedy
původní výraz \bftt{motorová pila} nejprve převedl na \bftt{motor pil} a
vykonal dotaz s tímto modifikovaným výrazem. Co se považuje za kmen slova je
určeno vybraným algoritmem. Kromě stematizace existuje ještě technika
lemmatizace, která místo kmenu slova hledá jeho základní (slovníkový) tvar.

V jazykové analýze existuje mnoho problémů. Především je závislá na konkrétním
jazyce. Může se stát, že některé datové kolekce obsahují záznamy ve více
jazycích. Pokud je text dostatečně dlouhý nebo obsahuje znaky specifické jen
pro daný jazyk, lze jazyk záznamu detekovat frekvenční analýzou před
morfologickým rozborem. V jiném případě může datová sada obsahovat záznamy v
jednom jazyce, ale jednotlivá slova mohou být v jiném. Pak jednoduchá
frekvenční analýza nebude dostačovat a museli bychom zvolit složitější techniky
pro jazykový rozbor, které jsou ale mimo rozsah této práce.

Problém s lemmatizací je také nejednoznačnost základního tvaru. Například slovo
\bftt{tancích} může mít základní tvar \bftt{tank} nebo \bftt{tanec} podle
významu slova, který by člověk určil z kontextu věty.

\url{https://is.muni.cz/th/256499/fi_m/thesis_sikora.txt}

% Aglutinativní jazyky
\subsection{Ngramy}
Alternativou k invertovaným indexům, kde invertovaný seznam odpovídá jednomu
lidskému slovu, jsou tzv. ngramové (qgram?) invertované indexy. Ngramem je
posloupnost několika po sobě jdoucích písmen o konstantní velikosti $n$.  Slovo
\bftt{motorka} obsahuje trigramy (ngram, kde $n = 3$) \bftt{mot, oto, tor,
ork, rka}.  Ngramový invertovaný index by pak měl invertovaný seznam pro každý
nalezený ngram. Velikou výhodu oproti slovnímu indexu je jazyková nezávislost a
podpora přibližného vyhledávání.

% TODO describe trigram indexes

Databázový systém postgres podporuje trigramový index díky jeho univerzálnosti.
\url{https://swtch.com/~rsc/regexp/regexp4.html}


\subsection{Inkrementální vyhledávání}
Z pohledu uživatele je velmi přívětivé, pokud se mu dostává zpětné vazby ještě
před tím, než dopíše svůj dotaz. V úplné formě se už během psaní dotazu
objevují první výsledky které by se objevily při potvrzení dotazu (typeahead
search, search as you type, real time search, ...). . Pro velké databáze se
inkrementální vyhledávání nepoužívá kvůli zvýšené výpočetní náročnosti. Namísto
toho se používá slabší forma inkrementálního vyhledávání - našeptávač
(autocompletion), který pouze nabízí uživateli nápovědu na dokončení jeho
dotazu. Pro nápovědu se používaje historie dotazů zadaných všemi uživateli
(query log) a našeptávač vrátí záznam, který maximalizuje podmíněnou
pravděpodobnost \bftt{P(<dotaz>|<nedokončený\_dotaz>)}. Pro relativně malé datové
sady je ale možné použít inkrementální vyhledávání v plné formě za cenu vyšší
zátěže na vyhledávač. Některé systémy to řeší ukládáním průběžných výsledků
nedokončených dotazů do mezipaměti s krátkou žívotností (cite tastier,
completesearch?).

\subsection{Prefixové vyhledávání}
V prefixovém inkrementálním vyhledávání uvažujeme, že dotaz, který uživatel v
danou chvíli zadává, je pouze část úplného dotazu. Pokud dokáže vyhledávač
hledat rychleji, než zadavatel píše, pak mu mohou být prezentovány záznamy s
potentiálním dokončeným dotazem prezentovány dříve, než dotaz dopíše. Např.
pokud je dotazem slovo \bftt{motor}, může se stát, že uživatel hledá slovo
\bftt{motorka} a dotaz ještě nedokončil. Pokud dotaz obsahuje více slov, pak
lze vyhledávač nastavit dvěma způsoby. V prvním případě dochází k prefixovému
vyhledávání pouze u posledního slova dotazu, pokud uvažujeme, že uživatel vždy
doplňuje pouze poslední slovo. Druhou variantou je, že umožníme uživateli
vyhledávat každé slovo jako prefix. Výhodou druhé metody z hlediska uživatele
je, že má částečně pod kontrolou morfologické změny slov. Protože k nim dochází
nejčastěji na koncích slov, může uživatel jednoduše vynechat koncovky slov a
vyhledávač mu je doplní. Např. při hledání slova \bftt{motork} by mohly být
nalezeny všechny záznamy obsahující tvary stejného slova (\textbf{motorka,
motorkou, motorkami}) nebo podobných slov (\textbf{motorkem, motorkář}).
Nevýhodou je velká výpočetní náročnost při vyhledávání krátkých prefixů.

\subsection{Hranové ngramy} Lze použít techniku hranových ngramů
(edge ngram), které kromě slova samotného zaindexují ještě všechny jeho
prefixy. Např. \bftt{motorka} se rozloží na \bftt{m, mo, mot, moto,
motor, motork, motorka}. Očividně pak i při nedokončeném dotazu
\bftt{moto} systém snadno dohledá úplné slovo. Jednou nevýhodou této
metody je náročnost na paměť - počet zaindexovaných slov i velikost
indexu roste kvadraticky s délkou textu. Proto se často omezuje délka
zaindexovaných hranových ngramů. Krátké ngramy se odfiltrují, protože
jich je příliš mnoho.  Vyhledávání jednoznakového ngramu může být
náročné až jako lineární průchod celou databází. Nevýhodou pak je, že
inkrementální vyhledávání nezačne fungovat už od prvního zadaného
písmene. Dlouhé ngramy se mohou odfiltrovat od maximální zvolené délky
ngramu a obdobná úprava se provede s dotazem. Příklad: indexujeme
hranové ngramy s délkou 2 až 4 znaků. Ze slova \bftt{motorka}
zaindexujeme odpovídající ngramy a celé slovo \bftt{mo, mot, moto,
motorka}. Při dotazu ořízneme slovo na maximální délku, abychom nalezli
shodu s nejdelším ngramem.  Tedy při vyhledávání slova \bftt{motork}
bude vyhledávač hledat záznamy, která obsahují buď \bftt{moto} nebo
\bftt{motorka}.

\subsection{Přibližné vyhledávání}
% describe ngrams fuzzy
Jiný způsob kromě ngramů, který umožňuje přibližné vyhledávání, je založený na
textové vzdálenosti mezi dvěma textovými řetězci. Jednoduchou textovou
vzdáleností je Hammingova vzdálenost. Ta se rovná počtu změněných znaků mezi
dvěma texty o stejné délce. Příklad: vzdálenost mezi slovy
\bftt{\boldred{m}oto\boldred{r}ka}, \bftt{\boldred{h}oto\boldred{v}ka} je 2,
protože se slova neshodují ve dvou znacích.

Jinou metrikou je editovací vzdálenost, která není omezená tím, že délka obou
textů musí být shodná. Editovací vzdálenost, stejně jako Hammingova vzdálenost,
udává počet záměn, ale navíc ještě počet odebraných nebo naopak přidaných
znaků. Příklad: Mezi slovy \bftt{kremrole}, \bftt{karel} je editovací
vzdálenost 5, protože slovo \bftt{kre\boldred{mro}l\boldred{e}} obsahuje 4 znaky navíc
a chybí mu 1 znak, který ale slovo \bftt{k\boldred{a}rel} obsahuje.

\section{Prefixové a fuzzy rozšíření indexu}
Ačkoliv se jedná o dva různé požadavky, prefixové a fuzzy invertované indexy
mají ve výsledku podobné vlastnosti a tudíž jsou pro ně vhodné stejné datové
struktury. Pokud na chvíli necháme fuzzy požavky stranou, nastíním, jak lze
jednoduše rozšířit klasický invertovaný index o podporu prefixového
vyhledávání.

Nevýhodou hranových ngramů je, že se může zaindexovat zbytečně mnoho ngramů.
Pokud je paměťová náročnost problém, lze namísto indexování pomocných ngramů
použít použít abecedně seřazený slovník všech zaindexovaných slov.  Všechna
slova odpovídající dotazovanému prefixu sa dohledají vybráním všech slov mezi
prvním a posledním slovem s daným prefixem. Ty lze snadno dohledat dvěma
binárními vyhledáními. Dotaz je výpočetně náročnější při vykonání, protože se
nejprve musí provést sjednocení všech invertovaných seznamů odpovídajících
jednomu prefixu před tím, než se provede průnik.

Díky morfologii, která se vyskytuje hlavně na koncích slov, bude index
přizpůsobený pro prefixové vyhledávání vhodný zároveň i pro fuzzy vyhledávání.
Většina podobných slov bude v seřazeném slovníku blízko u sebe. Pokud
vyhledáváme přibližná slova do editovací vzdálenosti 1, pak několik slov se
bude lišit v prvním znaku od dotazovaného, ale většina rozdílů bude v
pozdějších částech slova, a tedy ve výsledku budou relativně blízko u sebe.


\subsection{Trie}
Pro rychlý průchod slovníkem s přibližným prohledáváním je vhodná datová
struktura \textbf{trie} (radixový, prefixový strom). Trie je n-ární stromová
struktura, ve které je každé slovo uloženo tak, že se nejprve rozloží na znaky
a ty se ve stejném pořadí uloží jako jedna cesta ve stromu. Např. slovo
\bftt{motorka} by se ve stromu uložilo jako cesta \bftt{/m/o/t/o/r/k/a} od
kořene \bftt{/}, pokud bychom příklad přirovnali k hierarchii adresářů a
souborů v souborovém systému.

Trii je možné komprimovat (komprimovaná trie, compressed trie) sloučením po
sobě jdoucích znaků, které mají pouze jednoho potomka. Např. pokud existují
pouze dvě slova \bftt{motorka} a \bftt{motýl}, pak jejich cesty ve stromu
budou \bftt{/mot/orka} a \bftt{/mot/ýl} a budou sdílet prefix \bftt{/mot/}.
Je to vlastně seřazený seznam slov s tím, že všechny společné prefixy jsou
uloženy jako rodičovské uzly stromu n-árního stromu. Tohle rozložení nám umožní
rychle dohledat prefix, jehož potomci ve stromu jsou odpovědí na prefixový
dotaz.

Vyhledání podobných slov podle editovací vzdálenosti využije společných prefixů
tím, že společný prefix spočítá pouze jednou pro celou skupinu slov. (cite
Hanov).

\subsection{Jiné reprezentace slovníku}
\paragraph{Metrické stromy}
% describe BK, VP-TREE
\paragraph{Delete algoritmus}
\paragraph{Signature hashing}

\subsection{Hybridní index}
Velkou výpočetní zátěží u prefixových a fuzzy indexů je, pokud musí provést
disjunktivní sloučení (sloučení, OR) většího množství invertovaných seznamů.
Většinou v literatuře potkáme konjunktivní sloučení (průnik, AND), které je
naopak tím efektivnější, čím více invertovaných seznamů v něm učinkuje.
Analogicky ke konjunkci množin - čím více náhodných množin, tím menší je
pravděpodobnost, že bude jejich prvek ve všech najednou. U disjunkce platí, že
čím více množin, tím bude sloučená množina zpravidla větší.

Sloučení invertovaných seznamů je problém, pokud jejich množství narůstá.
Zejména to platí pro krátké prefixy, protože ve slovníku k nim budou
korespondovat tisíce slov. Problém velkého množství slov u krátkých prefixů je
i u hranových ngramů, jenže u nich jsou invertované seznamy předsloučeny během
indexování. Právě zde přichází myšlenka hybridního indexu, který během
indexování spolu předsloučí ty invertované seznamy, které mají velkou šanci, že
by byly sloučeny během vykonání dotazu (materializace invertovaných seznamů).
Tahle technika je obzvlášť vhodná pro čistě prefixové indexy bez fuzzy
rozšíření. Velkou pravděpodobnost sloučení totiž mají slova, která jsou
abecedně blízko sebe.

Pokud je index rozšířený o pozicovou informaci, pak sloučením všech
invertovaných záznamů získáme zpět původní datovou sadu, pouze zakódovanou
(dopředný index, forward index). Index se nazývá hybridní, protože je hybridem
mezi invertovaným a dopředným indexem.  Hybridní index je velmi podobný
dopřednému indexu v jednom z prvních popisů architektury Googlu. To, co se
myslí skupinou slov v hybridním indexu, odpovídá barelu (barrel) v jejich
indexu. S rozdílem, že oba pojmy slouží k jinému účelu. Jejich dopředný index
byla pouze mezifáze před vytvořením invertovaného indexu, zatímco u hybridního
indexu se tahle datová struktura struktura používá přímo k vyhledávání.

\subsubsection{HYB} je typ hybridního invertovaného indexu, který během
indexování předsloučí invertované seznamy slov v abecedním rozsahu.
Materializované seznamy mohou mít rozsahy např. \bftt{[A-EN], [EN-NUL],
[NUL-QU], [QU-Z]} - první invertovaný seznam by obsahoval slova
začínající na \bftt{A} až \bftt{EN}. Disjunktivní dotaz v téhle
struktuře je už buďto předsloučený, nebo během vykonání dotazu za běhu
sloučí pouze malé množství sousedících materializovaných seznamů. Ke
každému záznamu ve sloučeném seznamu musí být poznamenáno, ke kterému
slovu patří. Dotazy, které nevyužijí celý rozsah seznamu se díky této
dodatečné informaci vyfiltrují od slov, které zúženému rozsahu
neodpovídají. cite completesearch.

Tím, že jsou některé seznamy sloučeny do většího, budou dotazy, které by těchto
seznamů využily, penalizovány. Naopak komplexní disjunktivní dotazy budou
efektivnější než bez materializace. V klasickém invertovaném indexu je kvůli
zipfově distribuci velký nepoměr náročnosti při zpracování krátkých a dlouhých
seznamů. Hybridní index tenhle rozdíl srovnává za cenu, že původně efektivní
dotazy budou běžet zhruba stejně dlouho, jako ty původně náročné.

Bylo by možné materializovat všechny prefixy, které se ve slovníku budou
nacházet a prefixové dotazy by díky odpadnutí disjunkcí byly velmi efektivní,
ale u fuzzy dotazů nelze dopředu předpovědět, které invertované seznamy v nich
budou figurovat, protože závisí na dotazu. Tohle schéma by navíc bylo velmi
paměťově náročné. HYB oproti tomu, až na nutnost uložení identifikátoru slova
ke každému výskytu dokumentu, zabírá v paměti stejně místa jako obyčejný
invertovaný index


\section{Ohodnocovací funkce}

\subsection{tf.idf}
U dlouhého textu můžeme použít statistiky počtu slov k určení jeho
relevance k nějakému slovu. Na tomhle principu stojí většina
ohodnocovacích metod, které pracují s dlouhým textem.

$$
\bftt{tf.idf}_{t, d} = (1 + \log \bftt{tf}_{t, d}) \times \log_{10} N / \bftt{df}_{t}
$$

\bftt{tf} (term frequency) je počet výskytů slova v daném dokumentu. \bftt{df}
(document frequency) je počet výskytů slova v celé textové kolekci. \bftt{idf}
(inverse document frequency) je převrácená hodnota \bftt{df}.

\subsection{Předdefinované pořadí}

\subsection{Grafová analýza}
% page rank, centrality measures

\subsection{Blízkost}
Statistiky jako počet slov v textu ztrácí v krátkém textu význam. Film
nebude více zelený, pokud se v jeho názvu bude vícekrát vyskytovat slovo
\bftt{zelený} (cite algolia). V krátkém textu by byly nadměrně hodnoceny
delší texty, které slovo obsahují vícekrát, protože většina textů v
kolekci bude slovo obsahovat jenom jednou.

\subsection{Problémy ohodnocovacích funkcí}
Už od počátků velkých webových vyhledávačů v 90. letech se čistě textové
statistické metody založené na tf.idf zneužívaly, protože každý mohl
přizpůsobit text na své webové stránce, aby se lépe přizpůsobila
jednoduchým statistikám.

Stačí stránku zahltit co největším počtem různých slov (Keyword
stuffing), aby byla zvýšená pravděpodobnost, že ji vyhledávač uzná
relevantní při náhodném dotazu. Pro ještě větší úspěšnost lze důležitá
slova na stránce duplikovat pro zvýšení parametru \bftt{tf}.

% SEO - exploit of google's algorithms. Více vyhledávačů ztěžuje SEO



\chapter{Návrh nového systému}
\section{Podpora v existujících systémech}
\subsection{Apache Lucene}
% lucene, elastic, solr, algolia, xapian, mnogosearch, postgres


\subsection{Datové struktury}
Po uvážení běžně používaných a alternativních datových struktur pro index jsem
zvolil klasický invertovaný index s hybridní materializací. Pro slovník jsem
použil prefixovou trii, díky její podpoře pro efektivní prefixové i fuzzy
vyhledání slov. Invertovaný index je hybridní, protože se díky jeho
předsloučeným invertovaným seznamům hodí právě na prefixové a fuzzy dotazy,
které jsou klíčovou vlastností mého návrhu.

Vzdálenostní funkcí pro fuzzy vyhledávání ve slovníku jsem použil vzdálenostně
adaptovanou Levenshteinovu metriku kvůli lepšímu výkonu za cenu o něcoméně
přesných výsledků při překlepech na začátcích slov. Ve výsledku to není
problém, protože většina odlišností je až na konci slov kvůli povaze
morfologie.

Uvážil jsem i alternativní datové struktury pro index. Waveletové stromy jsou
vhodné pro velmi kompaktní uložení indexu a navíc mohou podporovat více pořadí
bez nutnosti ukládat index vícekrát. (cite dualsorted index). Protože se
soustředím na menší objemy dat, není kompaktnost až tak důležitá. Za druhé jsem
nenašel způsob, jak v něm uložit hybridní index, který má pro mé účely velkou
výhodu.

\subsection{Rozložení materializovaných skupin}
Pro hybridní materializaci jsem použil variaci na techniku popsanou
(completesearch) týmem. Rozložení skupin invertovaným seznamů u rozložení HYB
obecně nerespektuje abecední hranice. Důvodem je ten, že sloučené skupiny
invertovaných seznamů by měly být ideálně stejně dlouhé. Není to ale
jednoduché, protože se různá písmena objevují různě často. Např. obecně bude
existovat více slov začínající na \bftt{T} než těch, které začínají na
\bftt{x}. Kdyby se měla každá skupina shodovat alespoň v prvním písmenu, bylo
by to v rozporu s požadavkem na stejně dlouhé skupiny. Teoretickým řešením by
mohlo být předefinování abecedního pořadí dle frekvenční analýzy. Nejpočetnější
skupiny by mohly být rozděleny do více podskupin (např. \bftt{[TA-TD]},
\bftt{[TD-TM]}, \bftt{[TM-TZ]}), pro středně početné by existovala právě jedna
skupina a méně početné by byly sloučeny dohromady (např. \bftt{[U-X]},
\bftt{[X-Z]}). Kdyby se nepoužilo frekvenční pořadí, mohla by se mezi méně
početnými skupinami vyskytovat vysoce početná skupina zabraňující sloučení těch
okolních.

Tím, že používám vzdálenostně adaptovanou editační vzdálenost a většina slov
nalezených ve fuzzy dotazu bude mít podobný prefix, docházelo by k tomu, že
velká část seznamu bude nevyužita, protože se liší v prvním znaku. Rozmezí slov
u jedné skupiny může být např. \bftt{[J-M]} a dotaz by začínal na \bftt{M}. Slova v
seznamu začínající na \bftt{J}, \bftt{K} nebo \bftt{L} by v tomhle případě byla
nevyužita. Má úprava rozložení skupin oproti abecednímu rozložení u struktury
HYB se snaží zajistit, aby byly abecední hranice respektovány co nejvíce.
Výsledkem by měly být skupiny, jejichž hraniční slova sdílejí co nejdelší
prefixy.

\subsubsection{Algoritmus pro rozdělení skupin respektující abecední hranice}
Zařazení slova do slučující skupiny lze provést při prohledání trie do hloubky.
Začínáme na kořenovém uzlu s tím, že uvažujeme jedinou skupinu, do které na
začátku všechna slova patří. Pokud při průchodu součet délek invertovaných
seznamů poduzlů jednoho uzlu překročí stanovenou hranici, pak je dosavadní
přiřazená skupina uzlu nahrazena skupinou novou. Rekurzivní aplikací pro
všechny uzly se původně jedna skupina rozpadne na více skupin. Jediným
parametrem je hranice určující rozpadnutí skupiny, která může být staticky
daná, nebo být odvozená od dat. Zatím jsem ideální způsob, jak ji stanovit.


\subsection{Indexace}
Metody pro indexování u klasických invertovaných indexů se snaží vyhnout se
více průchody vstupní datovou sadou. Čtení vstupu z disku, parsování a
převádění na identifikátory je při velkých datových objemech časově náročné.
Rozložení do skupin u hybridního indexu - HYB i mé rozložení - vyžaduje
dvoufázové indexování, protože rozdělení do skupin potřebuje vědět statistiky,
ze kterých se určí, jak mají být sloučené skupiny velké.

V (fast HYB construction) autoři popisují techniku, jak použít jen několik
vzorků, aby s vysokou pravděpodobností určili velikost skupin. (cite a nastin
alg.)

Hybridní index se od klasického liší v počtu invertovaných seznamů. Klasický má
jeden seznam, byť potenciálně velmi krátký, pro každé vyskytující se slovo v
kolekci. Počet slov se odvíjí od heapsova zákona - tedy roste přibližně s
odmocninou velikosti kolekce - a pro velké kolekce je následně velký počet slov
důvodem indexačních technik pracujících s externí pamětí. Kvůli
charakteristikám pevných disků (pomalé posunutí čtecí hlavice při nesekvenčním
přístupu) a problému mít otevřených tisíce souborů najednou spočívají klasické
indexační algoritmy v tom, že zapisují částečné indexy sekvenčně na konec
jednoho souboru, a poté (nebo ještě za běhu) je postupně sloučí do většího.

% TODO describe block merge sort based

Hybridní index ale bude mít pouze omezené množství invertovaných seznamů, které
lze navíc korigovat. Autoři (cite completesearch) doporučují celkový počet
seznamů v řádu stovek - okolo 256. Díky tomu by nemělo být takovým problémem
vytvořit pro každý invertovaný seznam jeden soubor a vyhnout se slučovacímu
kroku.

\subsection{Problém korelovaných slov}
Jednou příčinou pomalých dotazů ve fuzzy vyhledávači je výskyt více podobných
slov v dotazu. Jednoduchým případem pro ilustraci je, pokud dotaz obsahuje více
totožných slov. Jejich invertované seznamy, případně disjunkce více
invertovaných seznamů, budou totožné. Dotaz ale proběhne beze změn, a tedy
provede jejich sloučení. Je snadno vidět, že sloučení dvou totožných seznamů
bude odpovídat dvojnásobku času průchodu pouze jedním seznamem.

O dvou podobných invertovaných seznamech můžeme hovořit jako o vysoce
korelovaných. Pokud slučujeme dva nízce korelované seznamy, pak jejich sloučení
bude relativně malá množina. Vysoce korelované dotazy trpí tím, že pozitivní
zmenšující efekt konjunkce u nich neplatí a navíc zvyšuje výpočetní náročnost
lineárně s každým takovým slovem.

Jednoduchým případem pro vyřešení je, pokud lze v dotazu identifikovat totožná
slova a jednoduše použít jen jedno z nich, protože průnik více stejných množin
neovlivní výsledek. Pouze se musí zajistit, že výsledky skutečně obsahují více
výskytů téhož slova, a to lze provést až v pozdější fázi po průchodem
invertovanými seznamy.

Těžším případem je, pokud se v dotazu vyskytují slova, která k sobě mají podle
editační vzdálenosti blízko. Jejich invertované seznamy, případně disjunkce
více seznamů, budou sdílet značnou část slov. Kvůli tomu budou jejich
invertované seznamy vysoce korelované a budou způsobovat degradaci dotazu.
Nicméně tohle už nelze řešit pouhým přepsáním dotazu odstraněním duplikovaných
slov.

Dalším problémem korelovaných slov je najít každému slovu v dotazu odpovídající
slovo ve výsledku bez překrytí, tj. pro každé slovo v dotazu, přestože může být
duplikované, musí být nalezen výskyt ve výsledném dokumentu, který ale nesmí
připadat jinému slovu z dotazu. Např. naivní technika deduplikování totožných
slov by způsobila, že dotaz \bftt{the the} by nalezl všechna slova, která
obsahují pouze jeden výskyt slova \bftt{the}. Nás ale budou zajímat výsledky,
které obsahují alespoň dva výskyty. Proto jsme v dotazu druhé \bftt{the} přece
použili.

Řešení není úplně snadné, protože algoritmicky odpovídá nalezení maximálního
párování v bipartitním grafu. Pro svou implementaci používám pouze jednoduchou
heuristiku, která zajistí, že neodfiltrovaný výsledek obsahuje alespoň tolik
výskytů, kolik má dotaz celkově slov. To zabrání případům, kdy více podobných
slov v dotazu zasáhne jediné vyskytující se slovo ve výsledku. Např. dotaz
\bftt{2015 - 2016} by nesprávně vrátil dokument \bftt{Grand Tour 2015}, protože
obě slova dotazu zasáhnou jediný výskyt \bftt{2015}. Tím, že nastolíme
požadavek, že výsledek musí mít alespoň tolik výsledků (zde 1), kolik je slov v
dotazu (zde 2), bude těmto primitivním případům zabráněno.



\subsection{Ohodnocení výsledků dotazu}
U dokumentů běžně uvažujeme náhodné pořadí, ale lze ho doupravit nějakým
preferenčním pořadím (podle času, podle ceny, počtu zhlédnutí, apod.). Přesto
by měla mít textová shoda největší význam, jinak by mohl mít uživatel pocit, že
si buď vyhledávač vymýšlí, má nízkou přesnost, nebo se mu někdo snaží něco
vnutit (např. upřednostněné produkty v eshopu).

Výpočetně by bylo výhodnější, pokud by se uvažovalo pouze předdefinované
pořadí, protože by bylo možné ho předpočítat během indexování a invertovaný
index seřadit podle něj. Případně ho uložit ve více pořadích za cenu více
potřebného úložného prostoru.

Předdefinované pořadí navíc ulehčuje předčasné ukončení vykonání dotazu (early
termination), protože nejdůležitější dokumenty budou nalezeny hned na začátku
invertovaných seznamů.

\subsection{Zvolení vah}
Celkové ohodnocení shody se vypočte jako součet všech dílčích faktorů
ohodnocených různými vahami. Důležitost textové shody by měla v první řadě být
určena vzdáleností výsledku od dotazu podle editační vzdálenosti. V druhé řadě
by to měla být minimální vzdálenost mezi slovy ve výsledku.  Tohle pořadí pak
může doupravit uživatelem zvolené pořadí, ale mělo by mít menší váhu než
textová shoda.

\subsubsection{Tie-breaking}
Jiný způsob výpočtu důležitosti používá implementace vyhledávače algolia
(tie-breaking). V něm se určí pořadí jednotlivých faktorů podle
důležitosti a nižší faktory se uvažují pouze pokud dojde ke shodě ve
vyšších faktorech. Např.  pokud je vzdálenost několika prvních výsledků
dotazu od dotazu 0 - tedy přesná shoda, pak teprve se přistoupí k
ohodnocení podle předdefinovaného pořadí, blízkosti, nebo jiného
faktoru. (cite algolia blog post).

\subsection{Blízkost}
Pro výpočet blízkosti slov dotazu ve výsledku jsem zvolil variaci na algoritmus
(plane sweep proximity match).


\chapter{Analýza}
\section{Implementované systémy}
Pro demonstraci uvedených technik jsem vytvořil tři vyhledávací systémy. První
z nich je má implementace hybridního indexu a zbylé dva jsou různé konfigurace
pro Elasticsearch sloužící k porovnání. Všechny porovnávané systémy odstraňují
diakritiku a převádějí velká písmena na malá při indexování i dotazování.
Všechny konfigurace jsou v příloze \ref{appendix:search_config}.

\subsection{Naivní řešení}
Jako základní řešení sloužící pro porovnání jsem nakonfiguroval Elasticsearch
tak, jak by se měl doporučeně nastavit pro full-textové vyhledávání ve větších
textových dokumentech. Text je stematizován zabudovaným stematizérem pro
češtinu. Cílem bude ukázat, že tohle nastavení bude mít potíže s vícejazykovou
datovou sadou, jmény a s některými případy morfologie v češtině.

\subsection{Trigramový vyhledávač}
Pro ukázku fuzzy vyhledávání pomocí ngramů jsem vytvořil další konfiguraci pro
Elasticsearch, která používá ngramy o minimální a maximální velikosti 3.

Pokud se použije ngramový filtr, pak není podporováno ngramové zvýrazňování
výsledků. Musí se použít ngramový tokenizér, který ale zahazuje všechny ngramy,
které jsou kratší než minimální délka ngramu. Řešením je vytvořit dodatečný
index se zahozenými krátkými slovy a při dotazování provést disjunkci
ngramového a tohoto indexu. Pro zpřesnění výsledků, pokud dojde k přesné shodě
slova v dotazu a v dokumentu, je do disjunkce přidán ještě třetí index s
původními neořezanými slovy.

Zvýrazňovač pro ngramy funguje, pouze pokud se použije \textit{Fast Vector
Highlighter}. Bohužel nezvýrazňuje správně, když se ngramy ve výsledku
překrývají. Je možné, že je chyba pouze ve verzi Elasticsearch, kterou
používám. Protože jsem nikde nenašel, jak tohle vyřešit, vytvořil jsem v
Pythonu dodatečný zvýrazňovač, aby zde prezentované výsledky byly srovnatelné s
ostatními systémy.

\subsection{Vlastní implementace}
Můj systém vychází z výše popsaného návrhu vyhledávacího systému. Implementace
je pouze prototyp napsaný v dynamicky typovaném Pythonu, a tedy nemůže z
výkonostního důvodu sloužit k porovnání rychlosti a jiných výkonnostních
veličin. Protože ale používám relativně malé datové sady, neměla by být
výkonnost překážkou. Prototyp slouží zejména jako demonstrace implementovaných
technik. Tou hlavní je výše popsaný modifikovaný hybridní invertovaný index se
slovníkem implementovaným jako trie.  Ohodnocovací funkce je čistě textově
založená - nemá o datech žádné vlastní předpoklady nebo přednostní pořadí. V
první řadě upřednostňuje shodu dotazu s výsledkem podle editační vzdálenosti -
pro každé slovo zvlášť. Dále pozitivně hodnotí ty výsledky, které obsahují
shodu s minimální poziční vzdáleností.  Shody výsledků se stejným ohodnocením
jsou pak rozbity několika minoritními hodnotami s nízkou váhou. Shoda, která je
více na začátku záznamu má přednost a shoda, která obsahuje více shodujících se
slov má přednost - obdobně jako u modelu tf.idf, pouze zde má velmi malou váhu
a neuvažuje relativní důležitost slova ve shodě (idf).

Dokonce při použití nového interpreteru pro Python s podporou JIT
kompilace PyPy vyhledávač dosahuje až srovnatelných rychlostí jako
Elasticsearch.


\section{Použité datové soubory}
Cílem je porovnat několik vyhledávačů na datových sadách s relativně krátkými
dokumenty, které mají navíc různé záludnosti jako výce jazyků, nebo slova
obtížně zpracovatelná jazykovou analýzou.

\subsubsection{ČSFD - filmy}
První datovou sadou jsou názvy filmů z Československé filmové databáze
(\url{http://csfd.cz}). Přestože je možné rozlišit jazyk filmu, protože
databáze tuto metainformaci obsahuje, sloučil jsem všechny názvy filmů
do jedné sady. V datové sadě se tedy film vyskytuje vícekrát, pokud má
více názvů.

V databázi je celkem \textbf{441\,173} filmů a k nim jsou přidány
alternativní názvy v jiných jazycích, kterých je dohromady dalších
\textbf{176\,266}.

\subsubsection{ČSFD - filmoví tvůrci}
Druhá datová sada jsou všichni tvůrců (herců, režisérů, scénáristů,
apod.) pocházejících rovněž z databáze ČSFD. Celkem obsahuje
\textbf{240\,659} jmen.

\subsubsection{Česká wikipedia - nadpisy článků}
Data z wikipedie lze stáhnout z \url{https://dumps.wikimedia.org/cswiki/}. Pro
nadpisy byl použit soubor \textbf{cswiki-20160111-all-titles.gz}, který
obsahuje \textbf{907\,094} položek.

%
%\begin{center}
%\begin{tabular}{lr}
%\textbf{jazyk/země} & \textbf{počet názvů filmů} \\
%\hline
%původní           & 441\,173  \\
%anglický          &  47\,196  \\
%USA               &  28\,981  \\
%Slovensko         &  13\,932  \\
%slovenský         &   9\,539  \\
%Japonsko          &   7\,477  \\
%Francie           &   7\,419  \\
%Německo           &   5\,783  \\
%Rusko             &   3\,344  \\
%Česko             &   3\,180  \\
%Kanada            &   2\,774  \\
%Itálie            &   2\,766  \\
%český             &   2\,159  \\
%Španělsko         &   1\,606  \\
%Finsko            &   1\,267  \\
%Austrálie         &   1\,171  \\
%Polsko            &   1\,061  \\
%Maďarsko          &      822  \\
%Čína              &      781  \\
%\end{tabular}
%\end{center}


\subsection{Databáze herců - ČSFD}

\section{Porovnání výsledků vyhledávání}
Všechny analyzované vyhledávače podle očekávání vrátí výsledek, pokud se v
jednotlivých slovech přesně shoduje s dotazem. Některé, zejména
\bftt{trigram\_ES}, vrací za cenu vyšší přesnosti více výsledků, aby se zvýšila
šance, že žádný relevantní výsledek nebude vynechán.  V následujících
výsledkových tabulkách je zobrazeno několik prvních výsledků vyhledávání pro
každý vyhledávač s uvedeným počtem celkových nalezených výsledků. Vedle každého
výsledku je uvedeno skóre, který daný vyhledávač přiřadil. Vyšší skóre zde
neznamená větší shodu, ale naopak označuje míru penalizace od perfektní shody.
Tedy menší skóre znamená přesnější shodu. Skóre nelze napříč vyhledávači
porovnávat (s výjimkou \bftt{edit} a \bftt{edit\_dyn}). Slouží jen pro
relativní porovnání shod v rámci jednoho vyhledávače.

\input{hits/forrest_gump.tex}

První příklad (tab.~\ref{tab:result:forrest_gump}) je dotaz, ve kterém hledáme
zahraniční film \bftt{Forrest Gump}, jehož jméno známe a umíme ho správně
napsat.

\clearpage
\subsection{Přesnost}
Několik následujících příkladů demonstruje záměrně zkomolené nebo jinak
nepřesné dotazy, od kterých ale beztak očekáváme přesný zásah.
Vyhledávače by neměly vracet příliš mnoho výsledků, protože tyto dotazy
budou relativně dlouhé a specifické, které by v omezených datových
sadách měly obsahovat jen několik shodujících se záznamů.

\input{hits/smrt_krasneho_srnce.tex}

Tab.~\ref{tab:result:smrt_krasneho_srnce} ukazuje schopnost vyhledávačů
vypořádat se s dotazem v jiném pádu a číslu, než je zamýšlený film. K
povšimnutí stojí rozdíl mezi vyhledávačem \bftt{edit} a jeho dynamickou
variantou \bftt{edit\_dyn}. Dynamická editovací vzdálenost má větší toleranci
pro odlišnosti na koncích slov, proto se dokázala vypořádat s editovací
vzdáleností \bftt{3} u rozdílu mezi \bftt{krásného} a \bftt{krásných}.
\bftt{edit} používá vzdálenost \bftt{3} až od délky slova \bftt{9}, jinak by
došlo k obrovskému nárůstu podobných slov.

\bftt{cs\_ES} nenašel žádnou shodu, přestože by jeho český stematizátor měl
tenhle případ zvládnout. Tím, že se jazyková analýza dotazu (\bftt{smrt krasnh
srnk}) neshoduje s analýzou výsledku (\bftt{smrt krasnych srnk}), nedojde ke
shodě. Vinou zde bude pouze nedostatečný základní stematizér v ElasticSearch.

\input{hits/sindleruv_seznam.tex}

Protože dynamická editovací vzdálenost upřednostňuje odlišnosti na
koncích slov oproti těm na začátcích, nenajde \bftt{edit\_dyn} shodu
filmu \bftt{Schindlerův seznam} při zkomoleném dotazu \bftt{Šindlerův
seznam}, který odpovídá fonetické reprezentaci - \bftt{Schi} je
nahrazeno českým \bftt{Ši} (tab.~\ref{tab:result:sindleruv_seznam}).

\input{hits/veznice_showsank.tex}

Na dotaz jiný zkomolený dotaz \bftt{Věznice Showsank}
(tab.~\ref{tab:result:veznice_showsank}, který by měl nalézt
\bftt{Vykoupení z věznice Shawshank} kladně reagují pouze \bftt{edit}
vyhledávače, protože cizí a specifický název \bftt{Shawshank} neprojde
jazykovou analýzou a trigramový systém selže, protože zasáhne pouze jeden
trigram \bftt{ank}.

Zvýrazňovač výsledků nebere v úvahu odstraněná písmena. Místo toho použije
délku dotazovaného slova nebo nejbližší mezeru, pokud je slovo delší. Kvůli
tomu není poslední písmeno slova \bftt{Shawshank} zvýrazněno, přičemž by mělo
být.

\input{hits/vezeni_showsank.tex}

Při zkomolení druhého slova už reaguje pouze \bftt{edit\_dyn}
(tab.~\ref{tab:result:vezeni_showsank}), protože ke zkomolení došlo na
konci slova.

\input{hits/prelet_kukacka.tex}

\begin{table}
\begin{tt}
\horizlina

\bftt{edit\_dyn} [2 nalezeno]\vspace{5pt}

\begin{tabulary}{1.1\textwidth}{LL}
11.64 & \boldred{Přelet} nad \boldred{kukaččí}m hnízdem \\
11.87 & Byl jednou jeden film: \boldred{Přelet} nad \boldred{kukaččí}m hnízdem \\
\end{tabulary}
\horizlina

\end{tt}
\caption{Výsledek dotazu \bftt{Přeletěla kukajda}}
\label{tab:result:preletela_kukajda}
\end{table}

U dotazu \bftt{přelet kukačka} v tab.~\ref{tab:result:prelet_kukacka} opět
selhal stematizér češtiny. Dotaz se převedl na \bftt{prelt kukack}, zatímco
záznam \bftt{Přelet nad kukaččím hnízdem} byl při indexování převeden na
neshodující se \bftt{prelt nad kukaccim hnizd}. \bftt{edit\_dyn} našel shodu i
pro velmi zkomolený dotaz (tab.~\ref{tab:result:preletela_kukajda}).

\input{hits/gottfather.tex}

Pokud chceme najít film s anglickým názvem \bftt{The Godfather} a nemůžeme si
vzpomenout, jak se to vlastně píše, vyhledávače využívající editovací
vzdálenost mohou napovědět. Trigramový nenašel shodu, kterou jsme hledali, ale
několik textově správných výsledků také našel.
(tab.~\ref{tab:result:gottfather}).

\input{hits/god_father.tex}

Obecně je u invertovaných indexů problém s oddělenými slovy. \bftt{edit},
\bftt{edit\_dyn} a \bftt{cs\_ES} indexují celá slova, zatímco
\bftt{trigram\_ES} indexuje trigramy. Příklad v
tab.~\ref{tab:result:god_father} je ukázkou, jak se vyhledávače zachovají, když
je cílovým dokumentem opět film \bftt{The Godfather}, ale dotaz je napsán jako
dvě oddělená slova \bftt{god} a \bftt{father}, ze kterých je kompozitní slovo
\bftt{godfather} složeno.


\subsection{Cizí jazyk a názvy}
\subsection{Oddělená slova}
\subsection{Krátký vstup}

\section{Rychlost vyhledávání}
\subsection{CPython a PyPy}
\subsection{Porovnání}

\section{Velikost indexu}

\chapter{Zhodnocení, další postup a otevřené problémy}
\section{Integrace do existujících systémů}
\section{Statické a dynamické indexy}
% static: no locks and latches, compact data structures, cache efficient
% 2 level data structure + bulk updates
% columnar storage
% document or term based
% share nothing
\section{Příliš krátký vstupní řetězec}
\section{Plánování dotazů}
\subsection{Škálovatelnost}
V této práci je mým cílem poukázat, že pro malá objemy dat je vhodné použít
adekvátní techniky pro zvýšení relevance vyhledávání za cenu zvýšené výpočetní
náročnosti. Tím, že jsou počítače stále výkonnější a datové sady se snadno
vejdou do dostupné paměti RAM, neměl by být při efektivní implementaci a
běžných dotazech s výkonem problém. Pokud jsou požadavkem větší objemy dat,
protože například firma roste s přibývajícím počtem zákazníků, pak by dnes
neměl být problém dokoupit si více paměti, která je každým rokem stále levnější.

I kdyby nepřipadalo v úvahu vertikální škálování přidáváním více RAM, existuje
možnost horizontálního škálování na více počítačů a vytvoření distribuovaného
systému. Invertované indexy jsou velmi snadno paralelizovatelné problémy
% TODO term or document distributed. cite something

Ten by ostatně byl nezbytný, pokud by požadavkem byla vysoká
dostupnost dat. Stejná data by byla replikována na více strojů a v případě
selhání jednoho by se instantně použila redundance více strojů.



\subsubsection{Indexování}
Implementace je zaměřená především na ty části, které jsou klíčové pro
demonstraci návrhu. Indexovací fáze používá jednoduchý \bftt{sort based}
algoritmus a nevyužívá techniky více souborů. Do budoucna by bylo užitečné
zjistit, jaké jsou nejvhodnější indexovací metody pro hybridní index oproti
klasickému invertovanému indexu.

\subsubsection{Porovnání výkonu}
Algoritmy pro slučování invertovaných seznamů jsou obzvlášť citlivé na správnou
implementaci a především na zvolený programovací jazyk. Zatímco Python je
ideální prototypovací jazyk, je asi tím nejhorším, v čem by měl být produkční
vyhledávací systém vytvořen. To se sice časem může změnit díky výkonově
orientovanému interpreteru PyPy. Přesto by měla být pro adekvátní porovnání
implementace provedena v jazyce s podporou překladu do nativního strojového
kódu.

Se zpomalujícím Mooreovým zákonem se objevují různé formy paralelismu, které by
měly sloužit jako náhrada za klesající tempo růstu. Pro pečlivě optimalizovaný
kód, které databázové a vyhledávací systémy často využívají, se častěji a
častěji využívají bitově-paralelní instrukce moderních procesorů. I z tohoto
důvodu by měl být zvolen takový jazyk, ve kterém není velkou překážkou tyto
moderní schopnosti procesorů využívat. (cite completesearch C++).


\chapter{Závěr}
Záměrem této práce je poukázat na alternativní přístupy v oblasti vyhledávání a
demonstrovat možný vyhledávací systém s alternativními technikami, který by byl
pro současné firemmní i nekomerční potřeby vhodnější, než systémy navrhované a
tvořené pro potřeby Webových vyhledávačů, které jsou však dnes nejrozšířenější.

\section*{Odkazy}
\url{http://www.dcs.gla.ac.uk/~craigm/publications/lacour08efficiency.pdf}

\newpage
\section*{Reference}
\bibliographystyle{csplainnat}
\bibliography{ref}

\appendix
\chapter{Konfigurace porovnaných systémů} \label{appendix:search_config}
\section{ElasticSearch}
\subsection{trigram\_ES}
\subsubsection{Analyzér}
\input{appendix/es_settings/trigram_analyzer.tex}

\subsubsection{Mapování}
\input{appendix/es_settings/trigram_mapping.tex}

\subsubsection{Dotaz pro vyhledávání}
\input{appendix/es_settings/trigram_search.tex}


\backmatter


\end{document}
